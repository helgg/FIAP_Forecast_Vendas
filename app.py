import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st

from pathlib import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score


try:
    from xgboost import XGBRegressor
    XGB_AVAILABLE = True
except Exception:
    XGB_AVAILABLE = False


st.set_page_config(
    page_title="Forecast de Vendas Semanais",
    layout="wide",
    initial_sidebar_state="expanded"
)
plt.rcParams["figure.figsize"] = (10, 3.2)  
plt.rcParams["axes.grid"] = False


def mape(y_true, y_pred):
    y_true = np.array(y_true); y_pred = np.array(y_pred)
    eps = 1e-9
    return np.mean(np.abs((y_true - y_pred) / np.clip(y_true, eps, None))) * 100

@st.cache_data(show_spinner=True)
def load_data(csv_path: Path):
    df = pd.read_csv(csv_path)
    df["Date"] = pd.to_datetime(df["Date"], dayfirst=True, errors="coerce")
    df = df.sort_values("Date").reset_index(drop=True)
    
    if (df["Fuel_Price"] > 100).any():
        df["Fuel_Price"] = df["Fuel_Price"] / 1000.0
    if (df["Unemployment"] > 100).any():
        df["Unemployment"] = df["Unemployment"] / 1000.0
    return df

def feature_engineering(df: pd.DataFrame):
    df = df.copy()
    df["year"] = df["Date"].dt.year
    df["month"] = df["Date"].dt.month
    df["weekofyear"] = df["Date"].dt.isocalendar().week.astype(int)
    df["quarter"] = df["Date"].dt.quarter
    df["is_month_start"] = df["Date"].dt.is_month_start.astype(int)
    df["is_month_end"] = df["Date"].dt.is_month_end.astype(int)
    
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)
    
    for lag in [1, 2, 3, 4, 12, 52]:
        df[f"Weekly_Sales_lag_{lag}"] = df["Weekly_Sales"].shift(lag)
    
    df["Weekly_Sales_roll_4"] = df["Weekly_Sales"].rolling(4).mean().shift(1)
    df["Weekly_Sales_roll_12"] = df["Weekly_Sales"].rolling(12).mean().shift(1)
    
    df = df.dropna().reset_index(drop=True)
    return df

def build_matrices(df: pd.DataFrame, cutoff="2012-01-01"):
    cutoff = pd.Timestamp(cutoff)
    train_df = df[df["Date"] < cutoff].copy()
    test_df  = df[df["Date"] >= cutoff].copy()

    target = "Weekly_Sales"
    feature_cols = [
        "Holiday_Flag","Temperature","Fuel_Price","CPI","Unemployment",
        "year","month","weekofyear","quarter",
        "is_month_start","is_month_end",
        "month_sin","month_cos",
        "Weekly_Sales_lag_1","Weekly_Sales_lag_2","Weekly_Sales_lag_3",
        "Weekly_Sales_lag_4","Weekly_Sales_lag_12","Weekly_Sales_lag_52",
        "Weekly_Sales_roll_4","Weekly_Sales_roll_12"
    ]

    X_train = train_df[feature_cols].copy()
    y_train = train_df[target].copy()
    X_test  = test_df[feature_cols].copy()
    y_test  = test_df[target].copy()

    return train_df, test_df, X_train, y_train, X_test, y_test, feature_cols

def iterative_forecast(model, X_test_scaled, lag_positions, scaler, original_X_test):
    Xt = X_test_scaled.copy()
    preds = []
    for i in range(Xt.shape[0]):
        p = model.predict(Xt[i].reshape(1, -1))[0]
        preds.append(p)
        if i + 1 < Xt.shape[0]:
            ref = original_X_test.iloc[[i+1]].copy()
            ref["Weekly_Sales_lag_1"] = p
            ref_scaled = scaler.transform(ref.values)
            Xt[i+1, lag_positions["Weekly_Sales_lag_1"]] = ref_scaled[0, lag_positions["Weekly_Sales_lag_1"]]
    return np.array(preds)

def kpi_table(y_test, preds_dict):
    rows = []
    for name, pred in preds_dict.items():
        rows.append({
            "Modelo": name,
            "RMSE": np.sqrt(mean_squared_error(y_test, pred)),
            "R¬≤": r2_score(y_test, pred),
            "MAPE (%)": mape(y_test, pred)
        })
    return pd.DataFrame(rows).sort_values("RMSE")


st.sidebar.title("‚öôÔ∏è Controles")
data_path = st.sidebar.text_input("Caminho do CSV", "sales.csv")
run_xgb = st.sidebar.checkbox("Comparar Modelos", value=True if XGB_AVAILABLE else False,
                              help="Se desmarcado apenas o melhor modelo ser√° exibido.")

# Estimators fixados -- Helder
# rf_trees = st.sidebar.slider("√Årvores (RandomForest)", min_value=300, max_value=1200, value=700, step=100)
# xgb_trees = st.sidebar.slider("√Årvores (XGBoost)", min_value=300, max_value=1500, value=800, step=100)
cutoff_str = st.sidebar.text_input("Data de corte (teste >=)", "2012-01-01")

st.sidebar.markdown("---")
st.sidebar.caption("Dica: ajuste a data de corte para ver como o modelo reage a per√≠odos diferentes.")


st.title("üìà Forecast de Vendas Semanais ‚Äî Dashboard Executivo")
st.caption("Previs√µes semanais com aprendizado de m√°quina (RandomForest e XGBoost), sem vazamento de dados, com foco em clareza para decis√£o.")

with st.expander("üß† O que voc√™ est√° vendo", expanded=True):
    st.write(
        """
        - **O que √©**: previs√µes semanais de vendas, usando um modelo que aprende com o comportamento passado e fatores de calend√°rio/economia.  
        - **Como funciona**: o modelo ‚Äúolha‚Äù as semanas anteriores (mem√≥ria), entende sazonalidade (meses do ano) e ajusta previs√µes semana a semana.  
        - **Por que confiar**: as previs√µes s√£o feitas **sem olhar o futuro** ‚Äî cada previs√£o alimenta a pr√≥xima, como aconteceria na opera√ß√£o real.  
        - **Como ler os KPIs**:
            - **RMSE**: quanto erramos, em m√©dia, nas unidades de venda. Menor √© melhor.  
            - **R¬≤**: quanto da varia√ß√£o das vendas o modelo explica (de 0 a 1). Maior √© melhor.  
            - **MAPE**: erro percentual m√©dio. Menor √© melhor.  
        """
    )


csv_path = Path(data_path)
if not csv_path.exists():
    st.error(f"Arquivo n√£o encontrado: {csv_path.resolve()}")
    st.stop()

df_raw = load_data(csv_path)
df = feature_engineering(df_raw)

train_df, test_df, X_train, y_train, X_test, y_test, feature_cols = build_matrices(df, cutoff=cutoff_str)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.values)
X_test_scaled  = scaler.transform(X_test.values)

lag_positions = {c: feature_cols.index(c) for c in feature_cols if "lag_" in c}


rf = RandomForestRegressor(
    n_estimators=700, #rf_trees
    max_depth=14,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train_scaled, y_train)

preds = {}
preds["RandomForest"] = iterative_forecast(
    model=rf,
    X_test_scaled=X_test_scaled,
    lag_positions=lag_positions,
    scaler=scaler,
    original_X_test=X_test
)

if run_xgb and XGB_AVAILABLE:
    xgb = XGBRegressor(
        n_estimators= 800, # xgb_trees
        learning_rate=0.05,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )
    xgb.fit(X_train_scaled, y_train)
    preds["XGBoost"] = iterative_forecast(
        model=xgb,
        X_test_scaled=X_test_scaled,
        lag_positions=lag_positions,
        scaler=scaler,
        original_X_test=X_test
    )
elif run_xgb and not XGB_AVAILABLE:
    st.warning("xgboost n√£o est√° instalado no ambiente. Desmarque a op√ß√£o ou instale com: pip install xgboost")


st.subheader("üî¢ KPIs de Precis√£o (per√≠odo de teste)")
kpis = kpi_table(y_test, preds)
col1, col2, col3 = st.columns(3)
col1.metric("Melhor RMSE", f"{kpis['RMSE'].min():,.0f}")
col2.metric("Melhor R¬≤", f"{kpis['R¬≤'].max():.2f}")
col3.metric("Melhor MAPE (%)", f"{kpis['MAPE (%)'].min():.2f}")
st.dataframe(kpis, use_container_width=True)

st.divider(width="stretch")
st.header("üìâ Real vs Previsto")
dates = test_df["Date"].reset_index(drop=True)
y_true = y_test.reset_index(drop=True)

def lineplot(y_true, y_pred, title):
    fig, ax = plt.subplots()
    ax.plot(dates, y_true, label="Real")
    ax.plot(dates, y_pred, label="Previsto")
    ax.set_title(title); ax.set_xlabel("Data"); ax.set_ylabel("Vendas Semanais"); ax.legend()
    st.pyplot(fig)

for name, pred in preds.items():
    st.space(size="small")
    st.subheader(f"{name}")
    if name == 'RandomForest':
        st.text('Este gr√°fico compara o valor real de vendas (linha azul) com o valor previsto pelo modelo (linha laranja) ao longo das semanas. Podemos observar que as duas linhas seguem um formato parecido, indicando que o modelo consegue capturar a tend√™ncia geral das vendas. Em algumas semanas existe uma diferen√ßa maior entre as linhas, o que normalmente acontece em per√≠odos com eventos fora do padr√£o, como promo√ß√µes, sazonalidade ou mudan√ßas de mercado.', help=None, width="content")
    else:
        st.text('Neste gr√°fico vemos a compara√ß√£o entre as vendas reais (linha azul) e as vendas previstas pelo modelo XGBoost (linha laranja). As duas linhas acompanham bem o movimento geral das vendas ao longo dos meses, mostrando que o modelo consegue entender a tend√™ncia e o comportamento do neg√≥cio. Em alguns pontos o modelo suaviza varia√ß√µes mais bruscas, o que √© comum em modelos que buscam estabilidade. No geral, o XGBoost apresenta boa ader√™ncia, especialmente em per√≠odos mais est√°veis, sendo √∫til para previs√µes de planejamento.', help=None, width="content")
    lineplot(y_true, pred, f"Real vs Previsto ‚Äî {name}")

st.space(size="small")
st.subheader("Comparativo entre os modelos")
st.text('Este gr√°fico coloca lado a lado as vendas reais e as previs√µes dos dois modelos. A linha azul representa o que realmente aconteceu, enquanto as linhas laranja (RandomForest) e verde (XGBoost) mostram as previs√µes. Observamos que ambos os modelos conseguem seguir a tend√™ncia geral das vendas ao longo do tempo. O XGBoost acompanha melhor oscila√ß√µes mais r√°pidas, ficando mais pr√≥ximo de picos e vales. J√° o RandomForest tende a ser mais conservador, suavizando varia√ß√µes e mantendo previs√µes mais est√°veis, o que √© importante para planejamento e tomada de decis√£o, evitando rea√ß√µes exageradas a semanas at√≠picas. Por isso, apesar de pequenas diferen√ßas, o RandomForest foi escolhido como modelo principal, por oferecer maior consist√™ncia e menor risco operacional no uso das previs√µes.', help=None, width="content")

if len(preds) > 1:
    fig, ax = plt.subplots()
    ax.plot(dates, y_true, label="Real")
    for name, pred in preds.items():
        ax.plot(dates, pred, label=name)
    ax.set_title("Comparativo ‚Äî Real x Modelos")
    ax.set_xlabel("Data"); ax.set_ylabel("Vendas Semanais"); ax.legend()
    st.pyplot(fig)

st.space(size="small")
st.divider(width="stretch")
st.header("üîç Diagn√≥stico de Erros")

def plot_error_over_time(dates, y_true, y_pred, title):
    e = np.array(y_true) - np.array(y_pred)
    fig, ax = plt.subplots()
    ax.plot(dates, e)
    ax.set_title(title)
    ax.set_xlabel("Data"); ax.set_ylabel("Erro (real - previsto)")
    st.pyplot(fig)

def plot_error_box_by_month(dates, y_true, y_pred, title):
    df_tmp = pd.DataFrame({"date": pd.to_datetime(dates), "err": np.array(y_true) - np.array(y_pred)})
    df_tmp["month"] = df_tmp["date"].dt.month
    data = [df_tmp[df_tmp["month"] == m]["err"].values for m in sorted(df_tmp["month"].unique())]
    fig, ax = plt.subplots()
    ax.boxplot(data, labels=sorted(df_tmp["month"].unique()))
    ax.set_title(title); ax.set_xlabel("M√™s"); ax.set_ylabel("Erro")
    st.pyplot(fig)

for name, pred in preds.items():
    st.space(size="small")
    if name == 'RandomForest':
        st.subheader(f"Erro ao longo do tempo ‚Äî RandomForest")
        st.text('Este gr√°fico mostra a diferen√ßa entre o valor real e o valor previsto pelo modelo em cada semana. Quando a linha est√° pr√≥xima de zero, significa que o modelo acertou bem. Os picos positivos e negativos representam semanas em que houve mudan√ßas fora do padr√£o, como promo√ß√µes, sazonalidade ou fatores externos. No geral, o modelo mant√©m o erro controlado e sem desvios prolongados, o que indica que ele √© est√°vel e adequado para uso no planejamento.', help=None, width="content")
        plot_error_over_time(dates, y_true, pred, f"Erro ao longo do tempo ‚Äî {name}")
        st.space(size="small")
        st.subheader(f"Erro ao longo do tempo ‚Äî RandomForest")
        st.text('Este gr√°fico mostra como o erro do modelo se comporta em cada m√™s. Meses onde a caixa √© mais alta ou espalhada indicam maior varia√ß√£o nas vendas, ou seja, semanas mais diferentes do padr√£o esperado. J√° meses com caixas mais compactas indicam que o modelo conseguiu prever com maior estabilidade. De forma geral, o modelo mant√©m um desempenho consistente ao longo do ano, com varia√ß√µes naturais em per√≠odos de maior movimenta√ß√£o ou sazonalidade.', help=None, width="content")
        plot_error_box_by_month(dates, y_true, pred, f"Erro por m√™s ‚Äî {name}")
    else:
        st.subheader(f"Erro ao longo do tempo ‚Äî XGBoost")
        st.text('Este gr√°fico mostra como o erro do XGBoost varia ao longo das semanas. Assim como no RandomForest, quando a linha est√° pr√≥xima de zero, o modelo acertou bem. Por√©m, percebemos picos mais intensos, tanto para cima quanto para baixo, indicando que o XGBoost √© mais sens√≠vel a mudan√ßas bruscas no comportamento das vendas. Essa maior oscila√ß√£o pode levar a previs√µes menos est√°veis em semanas at√≠picas. Por isso, mesmo apresentando bom desempenho, optamos pelo RandomForest como modelo principal, pois ele oferece maior equil√≠brio e consist√™ncia, o que √© mais seguro para o planejamento.', help=None, width="content")
        plot_error_over_time(dates, y_true, pred, f"Erro ao longo do tempo ‚Äî {name}")
        st.space(size="small")
        st.subheader(f"Erro ao longo do tempo ‚Äî XGBoost")
        st.text('Este gr√°fico mostra como o erro do XGBoost varia m√™s a m√™s. Percebemos que, em alguns meses, a distribui√ß√£o do erro √© mais espalhada, indicando que o modelo √© mais sens√≠vel a mudan√ßas bruscas no comportamento das vendas. Essa sensibilidade pode fazer com que o modelo reaja demais a semanas at√≠picas, ampliando o erro em per√≠odos de maior varia√ß√£o ou sazonalidade. Embora o XGBoost acompanhe bem oscila√ß√µes, essa maior instabilidade mensal refor√ßa a escolha do RandomForest como modelo principal, pois ele mant√©m previs√µes mais est√°veis e consistentes, o que √© ideal para o planejamento do neg√≥cio.', help=None, width="content")
        plot_error_box_by_month(dates, y_true, pred, f"Erro por m√™s ‚Äî {name}")


st.space(size="small")
st.divider(width="stretch")
st.header("üß© Import√¢ncia de Features (o que mais pesa nas previs√µes)")
def plot_feature_importance(importances, feature_names, title):
    idx = np.argsort(importances)[::-1]
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.bar(range(len(idx)), np.array(importances)[idx])
    ax.set_xticks(range(len(idx)))
    ax.set_xticklabels(np.array(feature_names)[idx], rotation=90)
    ax.set_title(title)
    st.pyplot(fig)
st.space(size="small")
st.subheader(f"RandomForest")
st.text('Este gr√°fico mostra quais informa√ß√µes o modelo mais utiliza na hora de prever as vendas. A vari√°vel com maior peso √© Weekly_Sales_lag_52, que representa as vendas da mesma semana do ano anterior. Isso indica que o neg√≥cio possui um forte padr√£o sazonal, ou seja, per√≠odos do ano tendem a repetir comportamentos de vendas. Outros fatores que tamb√©m influenciam as previs√µes s√£o a semana do ano, infla√ß√£o (CPI) e as vendas das semanas mais recentes, mostrando que o modelo aprendeu tanto o ciclo anual quanto o ritmo das √∫ltimas semanas. Em resumo: o modelo consegue capturar tend√™ncia + sazonalidade, o que refor√ßa sua capacidade de prever com consist√™ncia.', help=None, width="content")
plot_feature_importance(rf.feature_importances_, feature_cols, "RandomForest ‚Äî import√¢ncia")
if "XGBoost" in preds:
    st.space(size="small")
    st.subheader(f"XGBoost")
    st.text('Assim como no RandomForest, o XGBoost tamb√©m identifica a sazonalidade anual como o principal fator, com a vari√°vel Weekly_Sales_lag_52 sendo a mais relevante. Al√©m disso, o modelo d√° destaque √† semana do ano (weekofyear) e a indicadores econ√¥micos como CPI e Unemployment, mostrando que ele √© mais sens√≠vel a varia√ß√µes externas. Esse comportamento refor√ßa que o XGBoost reage mais rapidamente a mudan√ßas no ambiente, o que pode ser positivo, mas tamb√©m pode aumentar a instabilidade das previs√µes. Por isso, mesmo com boa capacidade de identificar padr√µes, optamos pelo RandomForest como modelo principal, pois ele mant√©m previs√µes mais est√°veis e adequadas para planejamento.', help=None, width="content")
    plot_feature_importance(xgb.feature_importances_, feature_cols, "XGBoost ‚Äî import√¢ncia")

st.space(size="small")
st.divider(width="stretch")
with st.expander("üìö Como ler este dashboard", expanded=True):
    st.markdown(
        """
**KPIs (no topo)**  
- **RMSE**: quanto erramos em valor absoluto.  
- **R¬≤**: o quanto explicamos da varia√ß√£o das vendas.  
- **MAPE**: erro percentual m√©dio.

**Gr√°ficos de linha**  
- Comparam vendas reais com as previs√µes. Linhas pr√≥ximas indicam boa ader√™ncia.

**Erro ao longo do tempo**  
- Se oscila ao redor de zero, o modelo est√° equilibrado.  
- Picos revelam semanas ‚Äúespeciais‚Äù (ex.: feriados, promo√ß√µes).

**Erro por m√™s (boxplot)**  
- Mostra meses onde o modelo √© mais inst√°vel.  
- √ötil para planejar a√ß√µes (ex.: refor√ßo de dados/vari√°veis em meses problem√°ticos).

**Import√¢ncia de Features**  
- Indica quais informa√ß√µes o modelo realmente usa para prever.  
- Se ‚Äúlags‚Äù aparecem no topo, o hist√≥rico recente √© muito relevante.
"""
    )


st.space(size="small")
st.html(

    """
    <div style="margin: 200px auto; text-align: center;">
        <h4>Anal√≠tico An√¥nimos</h4>
        <table style="margin: 0 auto; border-collapse: collapse; border: 1px solid white;">
            <tr>
                <th style="border: 1px solid white; padding: 6px;">Nome</th>
                <th style="border: 1px solid white; padding: 6px;">RM</th>
            </tr>
            <tr>
                <td style="border: 1px solid white; padding: 6px;">Cesar Miyashiro</td>
                <td style="border: 1px solid white; padding: 6px;">RM556286</td>
            </tr>
            <tr>
                <td style="border: 1px solid white; padding: 6px;">Helder Gualdi de Godoy</td>
                <td style="border: 1px solid white; padding: 6px;">RM556571</td>
            </tr>
            <tr>
                <td style="border: 1px solid white; padding: 6px;">Liora Vanessa Dopacio</td>
                <td style="border: 1px solid white; padding: 6px;">RM554355</td>
            </tr>
            <tr>
                <td style="border: 1px solid white; padding: 6px;">Marcelo Moure</td>
                <td style="border: 1px solid white; padding: 6px;">RM555751</td>
            </tr>
            <tr>
                <td style="border: 1px solid white; padding: 6px;">Sandro Fa√ßanha</td>
                <td style="border: 1px solid white; padding: 6px;">RM557585</td>
            </tr>
        </table>  
    </div>
    """
)
